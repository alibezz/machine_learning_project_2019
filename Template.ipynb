{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Template is created to make grading fair and straightforward. Anything not in the place as mentioned in the template would not be graded.\n",
    "\n",
    "<font color='red'> # NOTE: We would run the notebook through a Plagiarism Checker. If it is found to be copied, your work would not be graded, and the incident would be highlighted to NYU Authorities. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import csv training file given to us in the beginning of the project\n",
    "#we assume the file is in the same directory of this notebook\n",
    "df=pd.read_csv(\"qudditch_training.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop weight, finbourgh_flick, double_eight_loop due to missing information \n",
    "#and drop player_id due to not related to the target\n",
    "df.drop([\"weight\",\"finbourgh_flick\", \"double_eight_loop\",\"player_id\"], axis=1,inplace=True)\n",
    "\n",
    "#handling missing values by creating another category named 'U'\n",
    "columns_replace=[\"house\",\"player_code\",\"move_specialty\"]\n",
    "for column in columns_replace:\n",
    "\tdf[column].replace(\"?\",\"U\",inplace=True)\n",
    "df[\"gender\"].replace(\"Unknown/Invalid\",\"U\",inplace=True)\n",
    "\n",
    "#drop category 'U' from gender\n",
    "#only very few of rows have unknown type\n",
    "df = df[df.gender != 'U']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Datatype Conversion From Numeric to categoric and Vice-versa. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'api'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b3c294cd9997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mordered_satisfaction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Female\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Male\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mcat_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered_satisfaction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'api'"
     ]
    }
   ],
   "source": [
    "#define function for encoding (mapping)\n",
    "def map_features(features,df,dict):\n",
    "\tfor i in features:\n",
    "\t\tdf = df.replace({i:dict})\n",
    "\n",
    "\treturn df\n",
    "\n",
    "#reducing nominal values in snitchnip and stooging\n",
    "foul_dict={'None':'none','Norm':'norm','>7':'high','>8':'high','>200':'high','>300':'high'}\n",
    "foul_columns=[\"snitchnip\",\"stooging\"]\n",
    "df=map_features(foul_columns,df,foul_dict)\n",
    "\n",
    "#generate move specialty dict for reducing nominal values\n",
    "#1 stands for with specialty, 0 stands for without specialty\n",
    "def convert_move_specialty(df):\n",
    "\tdict={}\n",
    "\tfor i in df[\"move_specialty\"]:\n",
    "\t\tif i==\"U\":\n",
    "\t\t\tdict.update({\"U\":0})\n",
    "\t\telse:\n",
    "\t\t\tdict.update({i:1})\n",
    "\treturn dict\n",
    "\n",
    "move_spec_dict=convert_move_specialty(df)\n",
    "df=map_features([\"move_specialty\"],df,move_spec_dict)\n",
    "\n",
    "#23 tactics feature, ready for conversion\n",
    "tactics_columns=[\"body_blow\",\"checking\",\"dopplebeater_defence\",\"hawkshead_attacking_formation\",\"no_hands_tackle\",\"power_play\",\"sloth_grip_roll\",\"spiral_dive\",\"starfish_and_stick\",\"twirl\",\"wronski_feint\",\"zig-zag\",\"bludger_backbeat\",\"chelmondiston_charge\",\"dionysus_dive\",\"reverse_pass\",\"parkins_pincer\",\"plumpton_pass\",\"porskoff_ploy\",\"transylvanian_tackle\",\"woollongong_shimmy\"]\n",
    "\n",
    "#make a copy of dataframe for future use(feature reduction and extraction) before encoding\n",
    "df_tactics_change=df.copy()\n",
    "\n",
    "#convert tactics\n",
    "#Steady, Up, Down to 1, No to 0\n",
    "tactics_dict={'Steady':1,'No':0,'Up':1,'Down':1}\n",
    "df=map_features(tactics_columns,df,tactics_dict)\n",
    "\n",
    "#convert gender\n",
    "#Female to 0, Male to 1\n",
    "\n",
    "ordered_satisfaction = [\"Female\",\"Male\"]\n",
    "cat_dtype = pd.api.types.CategoricalDtype(ordered_satisfaction, ordered=True)\n",
    "df[\"gender\"]=df[\"gender\"].astype(cat_dtype).cat.codes\n",
    "\n",
    "#convert snitch_caught\n",
    "#No to 0, Yes to 1\n",
    "\n",
    "ordered_satisfaction = [\"No\",\"Yes\"]\n",
    "cat_dtype = pd.api.types.CategoricalDtype(ordered_satisfaction, ordered=True)\n",
    "df[\"snitch_caught\"]=df[\"snitch_caught\"].astype(cat_dtype).cat.codes\n",
    "\n",
    "#convert change\n",
    "#No to 0,Ch to 1\n",
    "\n",
    "ordered_satisfaction = [\"No\",\"Ch\"]\n",
    "cat_dtype = pd.api.types.CategoricalDtype(ordered_satisfaction, ordered=True)\n",
    "df[\"change\"]=df[\"change\"].astype(cat_dtype).cat.codes\n",
    "\n",
    "#covert target\n",
    "#NO to 0, YES to 1\n",
    "#ignore this part when transforming test data\n",
    "\n",
    "ordered_satisfaction = [\"NO\",\"YES\"]\n",
    "cat_dtype = pd.api.types.CategoricalDtype(ordered_satisfaction, ordered=True)\n",
    "df[\"quidditch_league_player\"]=df[\"quidditch_league_player\"].astype(cat_dtype).cat.codes\n",
    "\n",
    "#one-hot encoding rest of columns\n",
    "\n",
    "df=pd.get_dummies(df, columns=[\"house\",\"foul_type_id\",\"game_move_id\",\"penalty_id\",\"player_code\",\"player_type\",\"snitchnip\",\"stooging\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Reduction or extraction. (If ANY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sum num_games_satout, num_games_injured, num_games_notpartof and combine them into one feature named num_game_not_participate\n",
    "\n",
    "df[\"num_game_not_participate\"]=df.num_games_satout+df.num_games_injured+df.num_games_notpartof\n",
    "\n",
    "#sum up number of tactic changes into one feature named num_tactics_change\n",
    "\n",
    "#encoding dictionary for helping calculation\n",
    "#Up and Down count for change\n",
    "tactics_change_dict={'Steady':0,'No':0,'Up':1,'Down':1}\n",
    "\n",
    "#do encoding in the copy of dataframe, help calculation\n",
    "df_tactics_change=map_features(tactics_columns,df_tactics_change,tactics_change_dict)\n",
    "\n",
    "#initialize column filled by 0\n",
    "df[\"num_tactics_change\"]=0\n",
    "\n",
    "#define function for sum change of tactics\n",
    "def sum_change_tactics(df,df_copy,columns):\n",
    "\n",
    "\tfor i in columns:\n",
    "\n",
    "\t\tdf[\"num_tactics_change\"]+=df_copy[i]\n",
    "\n",
    "sum_change_tactics(df,df_tactics_change,tactics_columns)\n",
    "\n",
    "\n",
    "#sum up number of tactics used by each player\n",
    "#create new column named num_total_tactics\n",
    "\n",
    "df[\"num_total_tactics\"]=0\n",
    "def sum_tactics(df,columns):\n",
    "\n",
    "\tfor i in columns:\n",
    "\t\t\n",
    "\t\tdf[\"num_total_tactics\"]+=df[i]\n",
    "\n",
    "\treturn df\n",
    "\n",
    "sum_tactics(df,tactics_columns)\n",
    "\n",
    "#move target to the last column\n",
    "#ignore this part when transforming test data\n",
    "df_target=df[\"quidditch_league_player\"]\n",
    "df.drop([\"quidditch_league_player\"], axis=1,inplace=True)\n",
    "df.insert(len(df.columns),\"quidditch_league_player\", df_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Any other Pre-processing Used. (Give the name along with the code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-43e613085efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlog_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_transform_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#Standardization (v-mean)/std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#log transform\n",
    "\n",
    "log_transform_columns=[\"num_games_satout\",\"num_games_injured\",\"num_games_notpartof\"]\n",
    "def log_transform(df,columns):\n",
    "\n",
    "\tfor i in columns:\n",
    "\t\t#add 1 to original values to perform log transform\n",
    "\t\tdf[i]+=1\n",
    "\t\tdf[i]=df[i].apply(np.log)\n",
    "\n",
    "log_transform(df,log_transform_columns)\n",
    "\n",
    "#Standardization (v-mean)/std\n",
    "\n",
    "numeric_columns=[\"game_duration\",\"num_game_moves\",\"num_game_losses\",\"num_practice_sessions\",\"num_games_satout\",\"num_games_injured\",\"num_games_notpartof\",\"num_games_won\",\"age\",\"num_total_tactics\",\"num_game_not_participate\",\"num_tactics_change\"]\n",
    "def standardize_numeric_value(df,columns):\n",
    "\tscaler = StandardScaler()\n",
    "\tfor i in columns:\n",
    "\n",
    "\t\tdf[i]=scaler.fit_transform(df[i].values.reshape(-1,1))\n",
    "\n",
    "standardize_numeric_value(df,numeric_columns)\n",
    "\n",
    "#remove outliers\n",
    "def remove_outliers(df,columns):\n",
    "\n",
    "\tfor i in columns:\n",
    "\t\t\n",
    "\t\tdf = df[np.abs(df[i] - df[i].mean()) <= (3 * df[i].std())]\n",
    "\t\t\n",
    "remove_outliers(df,numeric_columns)\n",
    "\n",
    "#generate correlation matrix to observe\n",
    "df_corr=df.corr()\n",
    "df_corr.to_csv(\"correlation.csv\")\n",
    "\n",
    "df.to_csv(\"data_aftercleaned.csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1:\n",
    "Model Name: Logistic Regression<br>\n",
    "Evaluation method and metric used Name: 5-fold cross validation and the average F1-score for both classes<br>\n",
    "Name of the Hyperparameter used: Oversampling (SMOTE), C = 0.1, class_weight = None, penalty = 'L2', solver = 'sag'<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data_aftercleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5555d663d206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#below, we assume that the dataset generated in Part I is in the same folder of this notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_aftercleaned.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mkfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cross_validation_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mSKIP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;31m#TODO SEE IF SKIP IS NECESSARY!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5555d663d206>\u001b[0m in \u001b[0;36mprocess_input\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;31m#ignoring header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data_aftercleaned.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from collections import Counter\n",
    "from sklearn.utils import resample\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "SKIP = 2\n",
    "\n",
    "def get_cross_validation_folds(k):\n",
    "  kf = KFold(n_splits=k, random_state=RANDOM_STATE, shuffle=True)\n",
    "  return kf\n",
    "\n",
    "def separate_features_and_target(examples, target_index, feature_indices):\n",
    "  X = np.array([element[feature_indices] for element in examples])\n",
    "  y = np.array([element[target_index] for element in examples])  \n",
    "  return X, y\n",
    "\n",
    "def bootstrap_training(training_examples, training_classes):\n",
    "  #this is where we perform oversampling (SMOTE)\n",
    "  lcc = Counter(training_classes).most_common()[-1] #lcc is the Least Common Class\n",
    "  examples_in_lcc = [elem for i, elem in enumerate(training_examples) if training_classes[i] == lcc[0]]\n",
    "  #by doing so, you end up with the same number of samples per class  \n",
    "  number_of_samples = len(training_examples) - 2*len(examples_in_lcc) \n",
    "  new_samples = resample(examples_in_lcc, n_samples=number_of_samples, random_state=RANDOM_STATE)\n",
    "  training_examples = np.concatenate((training_examples, new_samples))\n",
    "  training_classes = np.concatenate((training_classes, [lcc[0] for i in new_samples]))\n",
    "  return training_examples, training_classes\n",
    "\n",
    "def get_fmeasure(precision, recall):\n",
    "  return (2.*precision*recall)/(precision+recall)\n",
    "\n",
    "def process_input(filename):\n",
    "  #ignoring header  \n",
    "  lines = [np.array([float(i) for i in l.strip().split(',')]) for l in open(filename, 'r').readlines()[1:]] \n",
    "  return np.array(lines)\n",
    "\n",
    "####### The functions above in this cell are useful for all models\n",
    "\n",
    "def logistic_regression(examples, kfolds, target_index, feature_indices, params={}, sampling=None):\n",
    "  lr = LogisticRegression(**params)\n",
    "  precs = []; recs = []; accs = []; fmeasures = []\n",
    "  for train_index, test_index in kfolds:\n",
    "    X_train, y_train = separate_features_and_target(examples[train_index], target_index, feature_indices)\n",
    "    if sampling == 'over': #bootstrap training samples in the minority class \n",
    "      X_train, y_train = bootstrap_training(X_train, y_train)\n",
    "    elif sampling == 'under': #reduce the number of samples in the majority class\n",
    "      X_train, y_train = undersample_training(X_train, y_train)\n",
    "    clf = lr.fit(X_train, y_train)\n",
    "    X_test, y_test = separate_features_and_target(examples[test_index], target_index, feature_indices)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    results = precision_recall_fscore_support(y_test, y_pred)\n",
    "    precs.append(results[0])\n",
    "    recs.append(results[1])\n",
    "    accs.append(clf.score(X_test, y_test))\n",
    "    fmeasures.append((get_fmeasure(results[0][0], results[1][0]), get_fmeasure(results[0][1], results[1][1])))\n",
    "  return accs, precs, recs, fmeasures\n",
    "\n",
    "#below, we assume that the dataset generated in Part I is in the same folder of this notebook\n",
    "examples = process_input('data_aftercleaned.csv') \n",
    "kfolds = get_cross_validation_folds(5)\n",
    "SKIP = 2 #TODO SEE IF SKIP IS NECESSARY!!\n",
    "num_features = len(examples[0]) - 1 #one field is the target\n",
    "\n",
    "best_params_logreg = {'C': 0.1, 'class_weight': None, 'penalty': 'l2', 'solver': 'sag'}\n",
    "sampling_logreg = 'over'\n",
    "print 'LOGISTIC REGRESSION'\n",
    "accs, precs, recs, fmeasures = logistic_regression(examples, kfolds.split(examples), -1,\n",
    "                                                   np.array([i + SKIP for i in xrange(num_features - SKIP)]),\n",
    "                                                   params=best_params_logreg, sampling=sampling_logreg)\n",
    "print 'average accuracy for folds', np.mean(accs)\n",
    "mean_overall_fmeasure = (np.mean([i[0] for i in fmeasures]) + np.mean([i[1] for i in fmeasures]))/2\n",
    "print 'average fmeasure for both classes', mean_overall_fmeasure \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2:\n",
    "Model Name: Adaboost<br>\n",
    "Evaluation method and metric used Name: 5-fold cross validation and the average F1-score for both classes<br>\n",
    "Name of the Hyperparameter used: Oversampling (SMOTE), weak classifiers are Decision Trees with max_depth = 1, n_estimators = 200, algorithm = 'SAMME'<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADABOOST\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-76164bc0f560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0msampling_adaboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'over'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'ADABOOST'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m accs, precs, recs, fmeasures = adaboost(examples, kfolds.split(examples), -1,\n\u001b[0m\u001b[1;32m     28\u001b[0m                                                    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSKIP\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mSKIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                    params=best_params_adaboost, sampling=sampling_adaboost)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'examples' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def adaboost(examples, kfolds, target_index, feature_indices, params={}, sampling=None):\n",
    "  ab =  AdaBoostClassifier(**params)\n",
    "  precs = []; recs = []; accs = []; fmeasures = []\n",
    "  for train_index, test_index in kfolds:\n",
    "    X_train, y_train = separate_features_and_target(examples[train_index], target_index, feature_indices)\n",
    "    if sampling == 'over': #bootstrap training samples in the minority class \n",
    "      X_train, y_train = bootstrap_training(X_train, y_train)\n",
    "    elif sampling == 'under': #reduce the number of samples in the majority class\n",
    "      X_train, y_train = undersample_training(X_train, y_train)\n",
    "    clf = ab.fit(X_train, [int(i) for i in y_train])\n",
    "    X_test, y_test = separate_features_and_target(examples[test_index], target_index, feature_indices)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    results = precision_recall_fscore_support(y_test, y_pred)\n",
    "    precs.append(results[0])\n",
    "    recs.append(results[1])\n",
    "    accs.append(clf.score(X_test, y_test))\n",
    "    fmeasures.append((get_fmeasure(results[0][0], results[1][0]), get_fmeasure(results[0][1], results[1][1])))\n",
    "  return accs, precs, recs, fmeasures \n",
    "\n",
    "weak_learner = DecisionTreeClassifier(max_depth=1)\n",
    "best_params_adaboost = {'base_estimator': weak_learner, 'n_estimators': 200, 'algorithm': 'SAMME'}\n",
    "sampling_adaboost = 'over'\n",
    "print 'ADABOOST'\n",
    "accs, precs, recs, fmeasures = adaboost(examples, kfolds.split(examples), -1,\n",
    "                                                   np.array([i + SKIP for i in xrange(num_features - SKIP)]),\n",
    "                                                   params=best_params_adaboost, sampling=sampling_adaboost)\n",
    "print 'average accuracy for folds', np.mean(accs)\n",
    "mean_overall_fmeasure = (np.mean([i[0] for i in fmeasures]) + np.mean([i[1] for i in fmeasures]))/2\n",
    "print 'average fmeasure for both classes', mean_overall_fmeasure \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3:\n",
    "Model Name:-----------<br>\n",
    "Evaluation method and metric used Name:-----------<br>\n",
    "Name of the Hyperparameter used:--------------......<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III: Best Hypothesis:\n",
    "Model Name:------------<br>\n",
    "Reason:--------------<br>\n",
    "Hyper-parameter Value:-----------<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
